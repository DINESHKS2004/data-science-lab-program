import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Load customer data
try:
    df = pd.read_csv("ecommerce_customers.csv")  # Replace with your dataset
except FileNotFoundError:
    print("Error: File 'ecommerce_customers.csv' not found.")
    exit()

print("ðŸ“Š Preview of Data:")
print(df.head())

# Step 2: Select relevant features for clustering
features = ['age', 'annual_income', 'spending_score', 'browsing_time', 'purchase_frequency']
X = df[features].dropna()

# Step 3: Standardize the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Step 4: Choose optimal number of clusters using Elbow Method
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, random_state=42)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)

# Plot Elbow Graph
plt.figure(figsize=(8, 4))
plt.plot(range(1, 11), wcss, marker='o')
plt.title("Elbow Method for Optimal k")
plt.xlabel("Number of clusters (k)")
plt.ylabel("WCSS")
plt.grid(True)
plt.tight_layout()
plt.show()

# Step 5: Fit KMeans with optimal number of clusters (e.g., k=4)
optimal_k = int(input("Enter the number of clusters (from Elbow graph): "))
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

# Step 6: Assign cluster labels to original data
df['Segment'] = clusters

# Step 7: Analyze clusters
print("\nðŸ“Š Customer Segment Distribution:")
print(df['Segment'].value_counts())

# Step 8: Visualize Segments
plt.figure(figsize=(8, 6))
sns.scatterplot(x='annual_income', y='spending_score', hue='Segment', data=df, palette='Set1')
plt.title("Customer Segments Based on Income & Spending")
plt.xlabel("Annual Income")
plt.ylabel("Spending Score")
plt.grid(True)
plt.tight_layout()
plt.show()

# Step 9: Save segmented data
df.to_csv("segmented_customers.csv", index=False)
print("\nâœ… Segmented customer data saved as 'segmented_customers.csv'.")
