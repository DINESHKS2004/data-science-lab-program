import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Load the dataset
try:
    df = pd.read_csv("retail_transactions.csv")  # Replace with your CSV file
except FileNotFoundError:
    print("Error: 'retail_transactions.csv' not found.")
    exit()

print("ðŸ“Š Dataset Preview:")
print(df.head())

# Step 2: Group by customer and aggregate
customer_df = df.groupby("customer_id").agg({
    "amount_spent": "sum",
    "visit_date": "count"  # Assuming visit_date is one row per visit
}).rename(columns={"amount_spent": "total_spent", "visit_date": "visit_frequency"})

# Step 3: Feature scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(customer_df)

# Step 4: Elbow method to find optimal k
wcss = []
for k in range(1, 11):
    km = KMeans(n_clusters=k, random_state=42)
    km.fit(X_scaled)
    wcss.append(km.inertia_)

plt.figure(figsize=(8, 4))
plt.plot(range(1, 11), wcss, marker='o')
plt.title("Elbow Method for Optimal Clusters")
plt.xlabel("Number of Clusters (k)")
plt.ylabel("WCSS")
plt.grid(True)
plt.tight_layout()
plt.show()

# Step 5: Use optimal k (e.g., from elbow graph)
optimal_k = int(input("Enter the number of clusters (based on elbow method): "))
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
customer_df['Segment'] = kmeans.fit_predict(X_scaled)

# Step 6: Analyze segments
print("\nðŸ§© Customer Segments Summary:")
print(customer_df.groupby('Segment').mean())

# Step 7: Visualize segments
plt.figure(figsize=(8, 6))
sns.scatterplot(data=customer_df, x="total_spent", y="visit_frequency", hue="Segment", palette="Set1")
plt.title("Customer Segmentation Based on Spending & Visits")
plt.xlabel("Total Amount Spent")
plt.ylabel("Visit Frequency")
plt.grid(True)
plt.tight_layout()
plt.show()

# Step 8: Save segmented customers
customer_df.to_csv("segmented_customers.csv")
print("\nâœ… Segmented customer data saved to 'segmented_customers.csv'")
