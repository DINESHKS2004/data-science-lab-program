import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split

# Load dataset
try:
    df = pd.read_csv("house_data.csv")  # Replace with your dataset
except FileNotFoundError:
    print("Error: 'house_data.csv' not found.")
    exit()

print("\nðŸ“Š Available columns in dataset:")
print(df.columns.tolist())

# Select feature and target
feature = input("\nEnter the feature to use for prediction (e.g., 'size'): ").strip()
if feature not in df.columns or 'price' not in df.columns:
    print("Error: Ensure both the feature and 'price' column are present in the dataset.")
    exit()

# Drop missing values
df = df[[feature, 'price']].dropna()

# Define X and y
X = df[[feature]]
y = df['price']

# Split into train/test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict on test set
y_pred = model.predict(X_test)

# Evaluate performance
r2 = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)

# Print evaluation metrics
print("\nðŸ“ˆ Model Performance:")
print(f"RÂ² Score: {r2:.4f}")
print(f"Mean Squared Error (MSE): {mse:.2f}")

# Visualize bivariate relationship and regression line
plt.figure(figsize=(8, 6))
plt.scatter(X_test, y_test, color='blue', label='Actual Prices')
plt.plot(X_test, y_pred, color='red', linewidth=2, label='Regression Line')
plt.xlabel(feature)
plt.ylabel("House Price")
plt.title(f"House Price vs. {feature.capitalize()}")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
